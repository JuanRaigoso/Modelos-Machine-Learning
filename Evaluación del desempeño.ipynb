{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2dfd98",
   "metadata": {},
   "source": [
    "# Evaluación del Desempeño de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254ee668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Cambiar el directorio de trabajo\n",
    "os.chdir('/Users/germanmejia/Desktop/MAESTRIA/2S/APRENDIZAJE AUTOMÁTICO/Módulo 1/Unidad 3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f6f85",
   "metadata": {},
   "source": [
    "# Etapa 1: Entendimiento de los Datos\n",
    "Este paso es crucial para familiarizarse con los datos que vamos a utilizar. Durante esta etapa, realizaremos una exploración de los datos incluyendo el tipo de datos, valores faltantes y resumen estadístico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ec4394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    B   G    R  Class\n",
      "0  74  85  123      1\n",
      "1  73  84  122      1\n",
      "2  72  83  121      1\n",
      "3  70  81  119      1\n",
      "4  70  81  119      1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Asumiendo que los datos están separados por espacios o un tabulador\n",
    "df = pd.read_csv('Skin_NonSkin.txt', delimiter='\\t', header=None, names=['B', 'G', 'R', 'Class'])\n",
    "\n",
    "data = df  # Cambia 'df' por el nombre de tu DataFrame si es diferente\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0878ba33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros: 245057\n",
      "Número de atributos: 4\n"
     ]
    }
   ],
   "source": [
    "# Cuál es el número de registros y atributos?\n",
    "shape = data.shape\n",
    "print(f'Número de registros: {shape[0]}')\n",
    "print(f'Número de atributos: {shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0657902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B        int64\n",
      "G        int64\n",
      "R        int64\n",
      "Class    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Cuál es el tipo de los atributos?\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b13ab891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   B              G              R          Class\n",
      "count  245057.000000  245057.000000  245057.000000  245057.000000\n",
      "mean      125.065446     132.507327     123.177151       1.792461\n",
      "std        62.255653      59.941197      72.562165       0.405546\n",
      "min         0.000000       0.000000       0.000000       1.000000\n",
      "25%        68.000000      87.000000      70.000000       2.000000\n",
      "50%       139.000000     153.000000     128.000000       2.000000\n",
      "75%       176.000000     177.000000     164.000000       2.000000\n",
      "max       255.000000     255.000000     255.000000       2.000000\n"
     ]
    }
   ],
   "source": [
    "# Medida de centralidad y desviación para atributos numéricos:\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e08b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación entre atributos numéricos\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Asumiendo que las columnas B, G, R son las características numéricas\n",
    "sns.heatmap(data[['B', 'G', 'R']].corr(), annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bcf48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificación de datos faltantes\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Máximo de datos faltantes en un mismo registro\n",
    "print(\"Máximo de datos faltantes en un registro:\", max(data.isnull().sum(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39d654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar desbalance de clases en 'Class'\n",
    "print(data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas numéricas B, G, R\n",
    "datos_numericos = data[['B', 'G', 'R']]\n",
    "# Crear una figura y un eje para el gráfico\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Crear los diagramas de cajas para B, G, R\n",
    "sns.boxplot(data=datos_numericos, orient=\"h\")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff5cf3",
   "metadata": {},
   "source": [
    "# Etapa 2: Preparación de los datos\n",
    "De acuerdo a lo observado en la etapa 1, se define una secuencia de actividades que modifican los datos para eliminar las situaciones que puedan ser causa de fallo o deficiencia en el proceso de aprendizaje. \n",
    "\n",
    "\n",
    "Algunas acciones que pueden realizarse son:\n",
    "- Eliminación o imputaciónde datos faltantes: En este caso no es necesario ya que no existe ningún dato faltante.\n",
    "- Normalizar los valores de los atributos: En este caso tampoco serán necesarios por que los atributos hacen referencia a  valores de color RGB que tienen una escala de 0-255. \n",
    "- Convertir los atributos categóricos a escala numérica: Tampoco será necesario ya que están en formato numérico\n",
    "- Balancear las clases eliminando registros de la clase mayoritaria o aumentando datos con diferentes técnicas de la clase minoritaria: En este caso, existe un  desbalance de clases. Sin embargo, primero se realizará el modelo con todos los datos para evaluar su rendimiento y luego se realizarán modificaciones para buscar el mejor modelo posible.\n",
    "- Eliminar variables muy correlacionadas: En la matriz de correlaciones se observa que B y G tienen una alta correlación (0.86) y podrían dar la misma información. Por lo que se puede eliminar una de ellas. Sin embargo, al igual que lo anterior, primero evaluaremos el rendimiento del modelo con la base de datos original y luego realizaremos unos ajustes para buscar el mejor modelo posible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e3cee7",
   "metadata": {},
   "source": [
    "**Rendimiento modelo conjunto de datos original**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y test\n",
    "X = data[['B', 'G', 'R']]  # Características\n",
    "y = data['Class']  # Etiqueta\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Entrenamiento del modelo de clasificación por regresión logística\n",
    "logisticRegr = LogisticRegression(solver=\"lbfgs\", max_iter=500, tol=0.01)\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "# Aplicación del modelo construido a los datos de test\n",
    "predictions = logisticRegr.predict(X_test)\n",
    "\n",
    "# Cálculo del accuracy para evaluar el desempeño del modelo sobre los datos de test\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy del modelo: {accuracy}')\n",
    "\n",
    "# Reporte de clasificación\n",
    "report = classification_report(y_test, predictions)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04669d5",
   "metadata": {},
   "source": [
    "**Rendimiento modelo con submuestreo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc864c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Crear una copia del DataFrame para mantener el original intacto\n",
    "data_subsampled = data.copy()\n",
    "\n",
    "# Separar el conjunto de datos por clase\n",
    "data_class_1 = data_subsampled[data_subsampled.Class == 1]\n",
    "data_class_2 = data_subsampled[data_subsampled.Class == 2]\n",
    "\n",
    "# Submuestrear la clase mayoritaria sin reemplazo para igualar el número de la clase minoritaria\n",
    "data_class_2_subsampled = resample(data_class_2, \n",
    "                                   replace=False, \n",
    "                                   n_samples=len(data_class_1), \n",
    "                                   random_state=42)\n",
    "\n",
    "# Combinar la clase minoritaria con la clase mayoritaria submuestreada\n",
    "data_balanced_subsampled = pd.concat([data_class_1, data_class_2_subsampled])\n",
    "\n",
    "# Mezclar los datos para evitar cualquier tipo de orden\n",
    "data_balanced_subsampled = data_balanced_subsampled.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b8c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos balanceado con submuestreo en conjuntos de entrenamiento y test\n",
    "X_subsampled = data_balanced_subsampled[['B', 'G', 'R']]\n",
    "y_subsampled = data_balanced_subsampled['Class']\n",
    "\n",
    "X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(\n",
    "    X_subsampled, y_subsampled, test_size=0.30, random_state=42)\n",
    "\n",
    "# Entrenamiento del modelo con el conjunto submuestreado\n",
    "logisticRegr_subsampled = LogisticRegression(solver=\"lbfgs\", max_iter=500)\n",
    "logisticRegr_subsampled.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "# Predicciones con el conjunto de prueba\n",
    "predictions_subsampled = logisticRegr_subsampled.predict(X_test_sub)\n",
    "\n",
    "# Evaluación del modelo submuestreado\n",
    "accuracy_subsampled = accuracy_score(y_test_sub, predictions_subsampled)\n",
    "print(f'Accuracy del modelo con submuestreo: {accuracy_subsampled}')\n",
    "print(classification_report(y_test_sub, predictions_subsampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67624d1",
   "metadata": {},
   "source": [
    "**Rendimiento modelo con sobrebmuestreo usando SMOTE**\n",
    "\n",
    "La técnica de SMOTE (Synthetic Minority Over-sampling Technique) es un método de balanceo de datos utilizado en machine learning para aumentar la cantidad de datos de las clases minoritarias. Funciona generando datos sintéticos, es decir, muestras artificiales, a partir de las existentes. SMOTE selecciona muestras aleatorias de la clase minoritaria, encuentra sus k vecinos más cercanos (usualmente en el espacio de características), y luego crea nuevas muestras que son combinaciones lineales de la muestra seleccionada y sus vecinos. Esto ayuda a evitar el sobreajuste que puede ocurrir con el sobremuestreo simple replicando datos, y mejora el rendimiento de los modelos al tener un conjunto de datos más equilibrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188cef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia del DataFrame para mantener el original intacto\n",
    "data_oversampled = data.copy()\n",
    "\n",
    "# Sobremuestrear la clase minoritaria con reemplazo para igualar el número de la clase mayoritaria\n",
    "data_class_1_oversampled = resample(data_class_1, \n",
    "                                    replace=True, \n",
    "                                    n_samples=len(data_class_2), \n",
    "                                    random_state=42)\n",
    "\n",
    "# Combinar la clase mayoritaria con la clase minoritaria sobremuestreada\n",
    "data_balanced_oversampled = pd.concat([data_class_2, data_class_1_oversampled])\n",
    "\n",
    "# Mezclar los datos para evitar cualquier tipo de orden\n",
    "data_balanced_oversampled = data_balanced_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imbalanced-learn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Crear una copia del DataFrame para mantener el original intacto\n",
    "X = data[['B', 'G', 'R']].copy()\n",
    "y = data['Class'].copy()\n",
    "\n",
    "# Inicializar SMOTE y sobremuestrear la clase minoritaria\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "# Convertir los resultados en un DataFrame\n",
    "data_balanced_smote = pd.DataFrame(X_smote, columns=['B', 'G', 'R'])\n",
    "data_balanced_smote['Class'] = y_smote\n",
    "\n",
    "# Mezclar los datos para evitar cualquier tipo de orden\n",
    "data_balanced_smote = data_balanced_smote.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8436d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos balanceado con sobremuestreo en conjuntos de entrenamiento y test\n",
    "X_oversampled = data_balanced_oversampled[['B', 'G', 'R']]\n",
    "y_oversampled = data_balanced_oversampled['Class']\n",
    "\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(\n",
    "    X_oversampled, y_oversampled, test_size=0.30, random_state=42)\n",
    "\n",
    "# Entrenamiento del modelo con el conjunto sobremuestreado\n",
    "logisticRegr_oversampled = LogisticRegression(solver=\"lbfgs\", max_iter=500)\n",
    "logisticRegr_oversampled.fit(X_train_over, y_train_over)\n",
    "\n",
    "# Predicciones con el conjunto de prueba\n",
    "predictions_oversampled = logisticRegr_oversampled.predict(X_test_over)\n",
    "\n",
    "# Evaluación del modelo sobremuestreado\n",
    "accuracy_oversampled = accuracy_score(y_test_over, predictions_oversampled)\n",
    "print(f'Accuracy del modelo con sobremuestreo: {accuracy_oversampled}')\n",
    "print(classification_report(y_test_over, predictions_oversampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6afbc0",
   "metadata": {},
   "source": [
    "**Rendimiento del modelo eliminando variables muy correlacionadas**\n",
    "\n",
    "La B y la G tienen una correlación positiva muy alta. Esto nos habla de que la información que aportan es muy similar y podría eliminarse una de ellas para reducir la dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una nueva copia del DataFrame sin la columna 'G'\n",
    "data_without_G = data.copy().drop('G', axis=1)\n",
    "# Dividir el nuevo conjunto de datos en características y etiquetas\n",
    "X_no_G = data_without_G.drop('Class', axis=1)\n",
    "y_no_G = data_without_G['Class']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train_no_G, X_test_no_G, y_train_no_G, y_test_no_G = train_test_split(\n",
    "    X_no_G, y_no_G, test_size=0.30, random_state=42)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "logisticRegr_no_G = LogisticRegression(solver=\"lbfgs\", max_iter=500)\n",
    "logisticRegr_no_G.fit(X_train_no_G, y_train_no_G)\n",
    "\n",
    "# Predicciones\n",
    "predictions_no_G = logisticRegr_no_G.predict(X_test_no_G)\n",
    "\n",
    "# Evaluación del modelo\n",
    "accuracy_no_G = accuracy_score(y_test_no_G, predictions_no_G)\n",
    "print(f'Accuracy del modelo sin la variable G: {accuracy_no_G}')\n",
    "print(classification_report(y_test_no_G, predictions_no_G))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031a602b",
   "metadata": {},
   "source": [
    "**Rendimiento modelo con submuestreo y eliminación de variables muy correlacionadas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2: Eliminar la variable 'G' del conjunto de datos submuestreado\n",
    "data_subsampled_no_G = data_subsampled.drop('G', axis=1)\n",
    "\n",
    "# Paso 3: Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_subsampled_no_G = data_subsampled_no_G.drop('Class', axis=1)\n",
    "y_subsampled_no_G = data_subsampled_no_G['Class']\n",
    "\n",
    "X_train_sub_no_G, X_test_sub_no_G, y_train_sub_no_G, y_test_sub_no_G = train_test_split(\n",
    "    X_subsampled_no_G, y_subsampled_no_G, test_size=0.30, random_state=42)\n",
    "\n",
    "# Paso 4: Entrenamiento del modelo de regresión logística\n",
    "logisticRegr_sub_no_G = LogisticRegression(solver=\"lbfgs\", max_iter=500)\n",
    "logisticRegr_sub_no_G.fit(X_train_sub_no_G, y_train_sub_no_G)\n",
    "\n",
    "# Paso 5: Predicciones con el conjunto de prueba\n",
    "predictions_sub_no_G = logisticRegr_sub_no_G.predict(X_test_sub_no_G)\n",
    "\n",
    "# Paso 6: Evaluación del modelo\n",
    "accuracy_sub_no_G = accuracy_score(y_test_sub_no_G, predictions_sub_no_G)\n",
    "print(f'Accuracy del modelo con submuestreo y sin la variable G: {accuracy_sub_no_G}')\n",
    "print(classification_report(y_test_sub_no_G, predictions_sub_no_G))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c72fd",
   "metadata": {},
   "source": [
    "**Comparación modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6493551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Resultados de los modelos\n",
    "resultados = {\n",
    "    \"Modelo\": [\n",
    "        \"Modelo Original\",\n",
    "        \"Modelo con Submuestreo\",\n",
    "        \"Modelo con Sobremuestreo\",\n",
    "        \"Modelo sin 'G'\",\n",
    "        \"Modelo con Submuestreo y sin 'G'\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        0.9190,\n",
    "        0.9436,\n",
    "        0.9409,\n",
    "        0.9170,\n",
    "        0.9170\n",
    "    ],\n",
    "    \"Precision (Macro Avg)\": [\n",
    "        0.87,\n",
    "        0.94,\n",
    "        0.94,\n",
    "        0.87,\n",
    "        0.87\n",
    "    ],\n",
    "    \"Recall (Macro Avg)\": [\n",
    "        0.88,\n",
    "        0.94,\n",
    "        0.94,\n",
    "        0.88,\n",
    "        0.88\n",
    "    ],\n",
    "    \"F1-Score (Macro Avg)\": [\n",
    "        0.88,\n",
    "        0.94,\n",
    "        0.94,\n",
    "        0.88,\n",
    "        0.88\n",
    "    ],\n",
    "    \"Precision (Weighted Avg)\": [\n",
    "        0.92,\n",
    "        0.94,\n",
    "        0.94,\n",
    "        0.92,\n",
    "        0.92\n",
    "    ],\n",
    "    \"Recall (Weighted Avg)\": [\n",
    "        0.92,\n",
    "        0.94,\n",
    "        0.94,\n",
    "        0.92,\n",
    "        0.92\n",
    "    ],\n",
    "    \"F1-Score (Weighted Avg)\": [\n",
    "        0.92,\n",
    "        0.94,\n",
    "        0.94,\n",
    "        0.92,\n",
    "        0.92\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Mostrar la tabla\n",
    "df_resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133833a1",
   "metadata": {},
   "source": [
    "# Etapa 3: Evaluación del modelo.\n",
    "\n",
    "Para la evaluación escogimos el modelo con mejor accuracy. es decir el modelo obtenido con el submuestreo. En esta etapa realizamos la evaluación con base a dos aspectos\n",
    "1. Validación Cruzada con N-folds (N=10).\n",
    "2. Random sub sampling 70/30con 10 repeticiones.\n",
    "\n",
    "A cada uno le calculamos lo siguiente: Matriz de confusión,Accuracy,Sensitivity o Recall, Specificity, Precision.\n",
    "F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f4c41",
   "metadata": {},
   "source": [
    "**Validación cruzada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4749c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Definir el número de divisiones para la validación cruzada\n",
    "n_splits = 10\n",
    "\n",
    "# Crear la instancia de StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Asumiendo que 'X' e 'y' ya están definidos, así como 'logisticRegr'\n",
    "\n",
    "# Inicializar listas para guardar las métricas de cada iteración\n",
    "conf_matrices = []\n",
    "accuracies = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1_scores = []\n",
    "specificities = []\n",
    "\n",
    "# Ejecutar la validación cruzada\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    logisticRegr.fit(X_train, y_train)\n",
    "    predictions = logisticRegr.predict(X_test)\n",
    "    \n",
    "    # Obtener y almacenar la matriz de confusión\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    TN = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    \n",
    "    # Calcular la especificidad y otros indicadores\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    specificities.append(specificity)\n",
    "    accuracies.append(accuracy_score(y_test, predictions))\n",
    "    recalls.append(recall_score(y_test, predictions, average='macro'))\n",
    "    precisions.append(precision_score(y_test, predictions, average='macro'))\n",
    "    f1_scores.append(f1_score(y_test, predictions, average='macro'))\n",
    "\n",
    "# Calcular y mostrar promedios de las métricas\n",
    "avg_specificity = np.mean(specificities)\n",
    "print(\"Promedio Matriz de Confusión:\\n\", np.mean(conf_matrices, axis=0))\n",
    "print(\"Promedio Accuracy:\", np.mean(accuracies))\n",
    "print(\"Promedio Recall:\", np.mean(recalls))\n",
    "print(\"Promedio Precision:\", np.mean(precisions))\n",
    "print(\"Promedio F1-Score:\", np.mean(f1_scores))\n",
    "print(\"Promedio Especificidad:\", avg_specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Tu matriz de confusión promedio obtenida de la validación cruzada\n",
    "conf_matrix = np.array([[4188.1, 897.8],\n",
    "                        [1092.5, 18327.3]])\n",
    "\n",
    "# Normalizar la matriz de confusión manualmente para la visualización de la matriz normalizada\n",
    "conf_matrix_normalized = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "# Etiquetas de clases para tu caso específico\n",
    "class_names = ['Clase 1', 'Clase 2']  # Ajusta según tus clases\n",
    "\n",
    "# Configuración de títulos para las matrices de confusión\n",
    "title_options = [\n",
    "    (\"Matriz de Confusión sin Normalización\", None),\n",
    "    (\"Matriz de Confusión Normalizada\", conf_matrix_normalized),\n",
    "]\n",
    "\n",
    "for title, matrix in title_options:\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    if matrix is None:\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n",
    "                                      display_labels=class_names)\n",
    "    else:\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=matrix,\n",
    "                                      display_labels=class_names)\n",
    "    disp.plot(include_values=True,\n",
    "              cmap=plt.cm.Blues, ax=ax, xticks_rotation='horizontal',\n",
    "              values_format='.2f' if title.find(\"Normalizada\") > -1 else '.0f')\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d633152d",
   "metadata": {},
   "source": [
    "**Random sub sampling 70/30con 10 repeticiones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14228a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Asumiendo que X, y, y logisticRegr ya están definidos\n",
    "\n",
    "# Inicializar listas para guardar las métricas de cada repetición, incluida la especificidad\n",
    "conf_matrices_rs = []\n",
    "accuracies_rs = []\n",
    "recalls_rs = []\n",
    "precisions_rs = []\n",
    "f1_scores_rs = []\n",
    "specificities_rs = []\n",
    "\n",
    "# Realizar 10 repeticiones de random subsampling\n",
    "for i in range(10):\n",
    "    X_train_rs, X_test_rs, y_train_rs, y_test_rs = train_test_split(X, y, test_size=0.30, random_state=i)\n",
    "    \n",
    "    logisticRegr.fit(X_train_rs, y_train_rs)\n",
    "    predictions_rs = logisticRegr.predict(X_test_rs)\n",
    "    \n",
    "    # Obtener la matriz de confusión\n",
    "    cm = confusion_matrix(y_test_rs, predictions_rs)\n",
    "    conf_matrices_rs.append(cm)\n",
    "    \n",
    "    # Calcular TN y FP para la especificidad\n",
    "    TN = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    specificities_rs.append(specificity)\n",
    "    \n",
    "    # Calcular otras métricas\n",
    "    accuracies_rs.append(accuracy_score(y_test_rs, predictions_rs))\n",
    "    recalls_rs.append(recall_score(y_test_rs, predictions_rs, average='macro'))\n",
    "    precisions_rs.append(precision_score(y_test_rs, predictions_rs, average='macro'))\n",
    "    f1_scores_rs.append(f1_score(y_test_rs, predictions_rs, average='macro'))\n",
    "\n",
    "# Calcular promedios de las métricas, incluyendo la especificidad\n",
    "avg_specificity_rs = np.mean(specificities_rs)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Random Subsampling - Promedio Matriz de Confusión:\\n\", np.mean(conf_matrices_rs, axis=0))\n",
    "print(\"Promedio Accuracy:\", np.mean(accuracies_rs))\n",
    "print(\"Promedio Recall:\", np.mean(recalls_rs))\n",
    "print(\"Promedio Precision:\", np.mean(precisions_rs))\n",
    "print(\"Promedio F1-Score:\", np.mean(f1_scores_rs))\n",
    "print(\"Promedio Especificidad:\", avg_specificity_rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Actualizar la matriz de confusión promedio obtenida del random subsampling\n",
    "conf_matrix = np.array([[12572.1, 2696.1],\n",
    "                        [3281.3, 54968.5]])\n",
    "\n",
    "# Normalizar la matriz de confusión manualmente para la visualización de la matriz normalizada\n",
    "conf_matrix_normalized = conf_matrix / conf_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Etiquetas de clases para tu caso específico\n",
    "class_names = ['Clase 1', 'Clase 2']\n",
    "\n",
    "# Configuración de títulos para las matrices de confusión\n",
    "title_options = [\n",
    "    (\"Matriz de Confusión sin Normalización\", conf_matrix),\n",
    "    (\"Matriz de Confusión Normalizada\", conf_matrix_normalized),\n",
    "]\n",
    "\n",
    "for title, matrix in title_options:\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=matrix,\n",
    "                                  display_labels=class_names)\n",
    "    disp.plot(include_values=True,\n",
    "              cmap=plt.cm.Blues, ax=ax, xticks_rotation='horizontal',\n",
    "              values_format='.2f' if title.find(\"Normalizada\") > -1 else '.0f')\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6fc05a",
   "metadata": {},
   "source": [
    "# Análisis y conclusión\n",
    "\n",
    "En este proyecto, hemos abordado el desafío de clasificar píxeles de imágenes en dos categorías: piel y no piel, utilizando un conjunto de datos que comprende valores de color en el espacio RGB. Nuestro enfoque metodológico se centró en explorar diferentes estrategias para mejorar el rendimiento de un modelo de regresión logística, dada la presencia de desequilibrio de clases y la correlación entre algunas características. \n",
    "\n",
    "Inicialmente, llevamos a cabo un análisis exploratorio para comprender la naturaleza de nuestros datos, confirmar la ausencia de valores faltantes y analizar la correlación entre las características. Observamos una alta correlación entre los canales de color azul (B) y verde (G), y un notable desequilibrio de clases, con una predominancia de píxeles no correspondientes a piel.\n",
    "\n",
    "Para abordar el desequilibrio de clases, implementamos dos estrategias: submuestreo de la clase mayoritaria y sobremuestreo de la clase minoritaria utilizando la técnica SMOTE. Además, experimentamos eliminando la característica 'G' para reducir la multicolinealidad.Posteriormente se evaluó el modelo con mejor rendimiento, es decir el modelo obtenido con el submuestreo mediante dos técnicas: validación cruzada N-folds (N=10) y random subsampling (70/30) con 10 repeticiones. Las métricas de evaluación incluyeron accuracy, precisión (macro y ponderada), recall (macro y ponderada), F1-score (macro y ponderada) y especificidad.\n",
    "\n",
    "La validación cruzada N-folds y el random subsampling tuvieron resultados muy similares. Esta consistencia sugiere que el modelo es estable y generaliza bien a nuevos datos, manteniendo un rendimiento sólido en todas las métricas clave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1ee93",
   "metadata": {},
   "source": [
    "**Fin**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
